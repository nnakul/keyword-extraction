## Keyword Extraction Using Word Embeddings
Word embeddings are used for representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning. This property of the word embeddings can be exploited to classify the entire vocabulary of words in the text into clusters, such that each cluster represents a unique emotion or a unique kind of information conveyed through the text. Lower the number of clusters, lower will be the level of disecting the semantics of the text. <br>
Keywords of a piece of information can be understood as a set of words such that no two words are very (or perhaps even moderately) similar and such that the overall decription of the text can be derived from just this set of words. In this case, clustering the word emeddings of every unique word of the text in the multi-dimensional space and keeping the center of each cluster as a keyword of the text can be an effective solution to capture the use of every word in the text. <br>
*KEYWORDS_EXTRACTION_WE.py* implements this idea of extracting the keywords from a text document. It uses the pre-trained *Word2Vec* model by *Google* (download <a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing"> here<a/>). In the preprocessing phase of the text, all the stopwords are removed. Another effective task that may be implemented is to do *re-sampling* by removing the words with very low (or very high) frequencies. In the clustering phase it was observed that as a result of getting different clusters each time the program is executed, sometimes almost all the keywords obtained are meaningful and sometimes some are not. Therefore, clustering algorithm is used a bit differently to obtain the most meaningful keywords. The set of keywords is initialized to all the words in the vocabulary of the pre-processed text. A loop is entered in which the set of center words of all the clusters is intersected with the current set of keywords. The loop terminates when the size of the keyword set drops below a limit. As a result of the repeated clustering, it is ensured that a word is treated as a keyword only if it is observed as the center of a cluster repeatedly. Despite of this technique the  
